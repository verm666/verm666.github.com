<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title type="text">Recent Blog Posts</title>
  <id>http://verm666.github.com/feed.atom</id>
  <updated>2012-03-17T00:00:00Z</updated>
  <link href="http://verm666.github.com/" />
  <link href="http://verm666.github.com/feed.atom" rel="self" />
  <subtitle type="text">Recent blog posts</subtitle>
  <generator>Werkzeug</generator>
  <entry xml:base="http://verm666.github.com/feed.atom">
    <title type="text">Ферма для XXX с хранилищем за день</title>
    <id>http://verm666.github.com/2012/03/17/xxx_farm</id>
    <updated>2012-03-17T00:00:00Z</updated>
    <link href="http://verm666.github.com/2012/03/17/xxx_farm" />
    <author>
      <name>verm666</name>
    </author>
    <content type="html">&lt;div class="section" id="id1"&gt;
&lt;h2&gt;Описание задачи&lt;/h2&gt;
&lt;p&gt;Предоставить сервис, который должен:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Принять запрос от клиента на получение видео файла;&lt;/li&gt;
&lt;li&gt;Получить видео данные в контейнере А от др. сервиса (назовем его L);&lt;/li&gt;
&lt;li&gt;Перепаковать в контейнер B;&lt;/li&gt;
&lt;li&gt;Сохранить полученный файл;&lt;/li&gt;
&lt;li&gt;Отдать полученный файл клиенту;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;При этом:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;При последующих запросах файла - он должен отдаваться без обращения к бэкенду;&lt;/li&gt;
&lt;li&gt;Если на сервис приходит одновременно несколько запросов за одним файлом -
на бэкенд должен уходить только первый, остальные ждут и получают результат первого.&lt;/li&gt;
&lt;li&gt;Должна быть предоставлена возможность перегенерации полученного файла;&lt;/li&gt;
&lt;li&gt;Ссылка на файл должна иметь время ограниченное жизни.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id2"&gt;
&lt;h2&gt;Размах проблемы&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&amp;gt; 20 000 запросов на изготовление файлов. Каждый размером ~ 100 МБ;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id3"&gt;
&lt;h2&gt;Оборудование, которое было под руками&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Сервер (далее S) с 32-мя 3ТБ дисками и 3ware RAID контроллером (9xxx серия);&lt;/li&gt;
&lt;li&gt;N серверов с памятью и процессорами (назовем их W) - будут заниматься обработкой видео.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id4"&gt;
&lt;h2&gt;Полученное решение&lt;/h2&gt;
&lt;div class="section" id="m"&gt;
&lt;h3&gt;Число M&lt;/h3&gt;
&lt;p&gt;Число M - максимальное число W-серверов в ферме. Выбирается один раз и навсегда.
Изменить его потом будет очень сложно. По сути является ограничением
масштабирования нашей фермы. Я взял 64. Красивое число да и W-серверов больше нет.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id5"&gt;
&lt;h3&gt;Хранилище&lt;/h3&gt;
&lt;p&gt;Первое о чем приходится задуматься - предоставление доступа к S-серверу с
любого W-сервера. При этом хочется иметь POSIX-совместимый доступ к файлам.&lt;/p&gt;
&lt;p&gt;Как ни странно связка XFS + NFS будет работать весьма неплохо. Да, в RW доступе.
Да, сразу на всех W-серверах. Нет, я не ебанулся.&lt;/p&gt;
&lt;p&gt;На самом деле сказанное выше (а именно RW доступ на всех W-серверах) не совсем
верно. Доступ будет, но мы не будем им пользоваться.&lt;/p&gt;
&lt;p&gt;В итоге:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Из всех дисков создаем RAID-6. Получаем 82 ТБ дискового пространства;&lt;/li&gt;
&lt;li&gt;Создаем на базе этого блочного устройства LVM VG;&lt;/li&gt;
&lt;li&gt;Нарезаем на M (смотри выше) LV;&lt;/li&gt;
&lt;li&gt;Создаем на них XFS;&lt;/li&gt;
&lt;li&gt;Монтируем в /storage/video/[1..M];&lt;/li&gt;
&lt;li&gt;Раздаем через NFS всем W-серверам в rw доступе.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;На этом настройка хранилища заканчивается. Больше о нем думать не надо.
Теперь надо просто добиться того, что бы в каждую отдельно взятую
точку монтирования отданную через NFS писал только 1 W-сервер. Этим
будет заниматься Балансер (Nginx).&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id6"&gt;
&lt;h3&gt;Балансер&lt;/h3&gt;
&lt;p&gt;Для балансировки запросов к W-серверам и хранилищу будет использоваться Nginx.&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;version &amp;gt;= 1.1.13 (из-за cache_lock);&lt;/li&gt;
&lt;li&gt;add ngx_secure_download;&lt;/li&gt;
&lt;li&gt;add ngx_mod_perl.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;На балансере точно так же как и на W-серверах монтируются все Logical Volume-ы
c S-сервера, только в ro режиме, так как писать нам на балансере не надо.&lt;/p&gt;
&lt;p&gt;Сразу приведу итоговый конф. файл, что бы было поянтно о чем я говорю:
&lt;a class="reference external" href="/static/my/xxx_farm_nginx.conf"&gt;nginx.conf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;На nginx приходят запросы вида: /video/uuid/begin-end.mp4/md5sum/hex_ts, где&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;uuid - некий ID, является идентификатором для обращения к сервису L;&lt;/li&gt;
&lt;li&gt;begin - timestamp начала получаемого файла;&lt;/li&gt;
&lt;li&gt;end - timestamp конца получаемого файла;&lt;/li&gt;
&lt;li&gt;md5sum/hex_ts - кусочки от ngx_secure_download.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;И так, пойдем по порядку:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Ограничение времени жизни ссылки на скачивание достигается через
ngx_secure_download;&lt;/li&gt;
&lt;li&gt;Балансировку между W-серверами и Logical Volume-ами S-сервера будет за нас
делать mod_perl, &lt;a class="reference external" href="http://www.cse.yorku.ca/~oz/hash.html"&gt;djb2&lt;/a&gt; и число M.
Таким образом запрос по конкретному uuid всегда будет уходить
на один и тот же W-сервер (см. map $shard $backend).
Итоговый файл для этого uuid всегда будет записываться в один и тот же
Logical Volume на S-сервере и запись в него будет производить только
один W-сервер.&lt;/li&gt;
&lt;li&gt;Удерживать одинаковые запросы к бэкенду будет cache_lock (если бы эта директива
не появилась в последних релизах - пришлось бы добавить еще Varnish. Так как до
недавнего времени именно этот кэш-сервер умел это делать);&lt;/li&gt;
&lt;li&gt;Возможность пересоздать файл предоставляется через отдельный server на др. порту
(можно было сделать просто отдельный location, но 80-й порт открыт в Internet);&lt;/li&gt;
&lt;li&gt;Отдача ранее сгенерированных файлов - try_files.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id7"&gt;
&lt;h3&gt;Бэкенд&lt;/h3&gt;
&lt;p&gt;Собстенно это небольшой python (flask + eventlet) сервис, который делает несколько
простых операций:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Забирает файл с сервиса L;&lt;/li&gt;
&lt;li&gt;Перепаковывает в конейнер B;&lt;/li&gt;
&lt;li&gt;Записывает файл в нужный Logical Volume;&lt;/li&gt;
&lt;li&gt;Через X-Accel-Redirect отдает файл в Nginx (см. location /internal_video).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Кстати, ленивые для подобных (или любых других операций) могут воспользоваться
&lt;a class="reference external" href="https://github.com/verm666/joyer"&gt;Joyer&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id8"&gt;
&lt;h3&gt;Еще пара слов про масшабирование&lt;/h3&gt;
&lt;p&gt;Добавление нового W-сервера приводит к тому, что мы добавляем его в
map $shard $backend. Равномерно распределяя shard-ы по бэкендам.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id9"&gt;
&lt;h2&gt;Выводы&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Если у вас есть возможность что-то вынести в mod_perl в Nginx - это
стоит сделать (сходить в memcache, посмотреть в cookie или как в этом случае -
получить возможность однозначной балансировки от некоторой переменной);&lt;/li&gt;
&lt;li&gt;Если включать мозг - наличие NFS в проекте не всегда плохо.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id10"&gt;
&lt;h2&gt;Литература по теме&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Nginx Secure Download - &lt;a class="reference external" href="http://wiki.nginx.org/HttpSecureDownload"&gt;http://wiki.nginx.org/HttpSecureDownload&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Message Authentication Code - &lt;a class="reference external" href="http://en.wikipedia.org/wiki/Message_authentication_code"&gt;http://en.wikipedia.org/wiki/Message_authentication_code&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;djb2 - &lt;a class="reference external" href="http://www.cse.yorku.ca/~oz/hash.html"&gt;http://www.cse.yorku.ca/~oz/hash.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Nginx cache_lock - &lt;a class="reference external" href="http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_cache_lock"&gt;http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_cache_lock&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;nginx.conf - &lt;a class="reference external" href="http://verm666.name/static/my/xxx_farm_nginx.conf"&gt;http://verm666.name/static/my/xxx_farm_nginx.conf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;joyer - &lt;a class="reference external" href="https://github.com/verm666/joyer"&gt;https://github.com/verm666/joyer&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="p-s"&gt;
&lt;h2&gt;P.S.&lt;/h2&gt;
&lt;p&gt;XXX - это не значит, что решение используется в сфере связанной с порнографией ;).&lt;/p&gt;
&lt;/div&gt;
</content>
  </entry>
</feed>

